{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/samiraabnar/Codes/GoogleLM1b/')\n",
    "sys.path.append('/Users/samiraabnar/Codes/Bridge/')\n",
    "\n",
    "from ExplainBrain import ExplainBrain\n",
    "from read_dataset.harrypotter_data import HarryPotterReader\n",
    "from computational_model.text_encoder import TfHubElmoEncoder, TfTokenEncoder, TfHubLargeUniversalEncoder, GloVeEncoder, GoogleLMEncoder\n",
    "from mapping_models.sk_mapper import SkMapper\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_dir = '/Users/samiraabnar/Codes/Data/harrypotter/'\n",
    "subject_ids = [1]\n",
    "brain_data_reader = HarryPotterReader(data_dir=brain_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/samiraabnar/Codes/Data/harrypotter/subject_1.mat\n",
      "Reading /Users/samiraabnar/Codes/Data/harrypotter/subject_1.mat\n",
      "Reading /Users/samiraabnar/Codes/Data/harrypotter/subject_1.mat\n",
      "Reading /Users/samiraabnar/Codes/Data/harrypotter/subject_1.mat\n"
     ]
    }
   ],
   "source": [
    "all_events = brain_data_reader.read_all_events(subject_ids=subject_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences per block:  {1: 115, 2: 163, 3: 134, 4: 177}\n",
      "average sentence length per block\n",
      "block  1 :  10.0 11.330434782608696 1 44\n",
      "sentences larger than 10: 56\n",
      "block  2 :  6.0 8.28834355828221 1 74\n",
      "sentences larger than 10: 48\n",
      "block  3 :  5.0 7.902985074626866 1 36\n",
      "sentences larger than 10: 35\n",
      "block  4 :  5.0 8.265536723163843 1 80\n",
      "sentences larger than 10: 53\n"
     ]
    }
   ],
   "source": [
    "number_of_sentences = {}\n",
    "sentences_length = {}\n",
    "subject_id = 1\n",
    "for block in all_events[subject_id]:\n",
    "    number_of_sentences[block.block_id] = len(block.sentences)\n",
    "    sentences_length[block.block_id] = []\n",
    "    for sent in block.sentences:\n",
    "        sentences_length[block.block_id].append(len(sent))\n",
    "    \n",
    "print(\"number of sentences per block: \", number_of_sentences)  \n",
    "print(\"average sentence length per block\")\n",
    "for block in [1,2,3,4]:\n",
    "    print(\"block \", block,\": \",np.median(sentences_length[block]),np.mean(sentences_length[block]), min(sentences_length[block]), max(sentences_length[block]))\n",
    "    print(\"sentences larger than 10:\", len(np.where(np.asarray(sentences_length[block]) > 10)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = np.load('/Users/samiraabnar/Codes/bridge_data/processed/harrypotter/1_none_window0-0_stimuli_in_context.npy').item()\n",
    "time_steps = np.load('/Users/samiraabnar/Codes/bridge_data/processed/harrypotter/1_none_window0-0_time_steps.npy').item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_dic_per_block = {1:{},2:{},3:{},4:{}}\n",
    "stimuli_dic_general = {}\n",
    "for block in [1,2,3,4]:\n",
    "    for stim, index in  stimuli[block]:\n",
    "        stim = ' '.join(stim)\n",
    "        if index is not None:\n",
    "            if not stim in stimuli_dic_per_block[block]:\n",
    "                stimuli_dic_per_block[block][stim] = 0\n",
    "            if not stim in stimuli_dic_general:\n",
    "                stimuli_dic_general[stim] = 0\n",
    "            stimuli_dic_per_block[block][stim] += 1\n",
    "            stimuli_dic_general[stim] += 1                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique stimuli and total number of stimuli\n",
      "1292 1295\n",
      "block  1 :  326 326\n",
      "block  2 :  338 338\n",
      "block  3 :  265 265\n",
      "block  4 :  366 366\n",
      "on the ground and 2\n",
      "the portrait of the 2\n",
      "+ It was a 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique stimuli and total number of stimuli\")\n",
    "print(len(stimuli_dic_general.keys()), sum(stimuli_dic_general.values()))\n",
    "for block in [1,2,3,4]:\n",
    "    print(\"block \",block,\": \",len(stimuli_dic_per_block[block].keys()), sum(stimuli_dic_per_block[block].values()))\n",
    "   \n",
    "for stim, count in stimuli_dic_general.items():\n",
    "    if count > 1:\n",
    "        print(stim, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_stimuli = []\n",
    "full_steps = []\n",
    "full_blocks = []\n",
    "for block in [1,2,3,4]:\n",
    "  for stim_in_c, step in zip(stimuli[block],time_steps[block]):\n",
    "    stim = list(np.asarray(stim_in_c[0])[0 if stim_in_c[1] is None else stim_in_c[1]])\n",
    "    if len(stim) == 0:\n",
    "      stim =[' ']\n",
    "    full_stimuli.extend(stim)\n",
    "    full_steps.extend([step]*len(stim))\n",
    "    full_blocks.extend([block]*len(stim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_general = {}\n",
    "vocab_per_block = {1:{},2:{},3:{},4:{}}\n",
    "\n",
    "for token,block in zip(full_stimuli,full_blocks):\n",
    "    if len(token.strip()) > 0:\n",
    "        if token not in vocab_general:\n",
    "            vocab_general[token] = 0\n",
    "        if token not in vocab_per_block[block]:\n",
    "            vocab_per_block[block][token] = 0\n",
    "        vocab_general[token] += 1  \n",
    "        vocab_per_block[block][token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab size: 1362\n",
      "total number of words: 6558\n",
      "block  1 :  553 1583\n",
      "block  2 :  560 1711\n",
      "block  3 :  461 1411\n",
      "block  4 :  583 1853\n"
     ]
    }
   ],
   "source": [
    "print(\"total vocab size:\", len(vocab_general.keys()))\n",
    "print(\"total number of words:\", sum(vocab_general.values()))\n",
    "\n",
    "for block in [1,2,3,4]:\n",
    "    print(\"block \",block,\": \",len(vocab_per_block[block].keys()), sum(vocab_per_block[block].values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many words occur only once:\n",
      "779\n",
      "how many words occur more than twice:\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "print(\"how many words occur only once:\")\n",
    "print(len(np.where(np.asarray(list(vocab_general.values())) == 1)[0]))\n",
    "\n",
    "print(\"how many words occur more than twice:\")\n",
    "print(len(np.where(np.asarray(list(vocab_general.values())) > 2)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
